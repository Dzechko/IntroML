{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7417fd80-94b2-4f86-af5b-7661352dcf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4978 - accuracy: 0.8241\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3725 - accuracy: 0.8661\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3361 - accuracy: 0.8776\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3116 - accuracy: 0.8855\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2938 - accuracy: 0.8913\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2824 - accuracy: 0.8951\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2660 - accuracy: 0.9020\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2592 - accuracy: 0.9031\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2492 - accuracy: 0.9069\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2400 - accuracy: 0.9112\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2323 - accuracy: 0.9129\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2241 - accuracy: 0.9162\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2172 - accuracy: 0.9194\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2123 - accuracy: 0.9205\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2048 - accuracy: 0.9238\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2005 - accuracy: 0.9243\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1946 - accuracy: 0.9261\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1894 - accuracy: 0.9291\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1835 - accuracy: 0.9315\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1800 - accuracy: 0.9328\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1776 - accuracy: 0.9334\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1717 - accuracy: 0.9352\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1677 - accuracy: 0.9365\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1638 - accuracy: 0.9377\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1583 - accuracy: 0.9405\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1558 - accuracy: 0.9412\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1541 - accuracy: 0.9420\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1493 - accuracy: 0.9441\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1467 - accuracy: 0.9447\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1449 - accuracy: 0.9459\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1412 - accuracy: 0.9470\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1385 - accuracy: 0.9480\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1357 - accuracy: 0.9488\n",
      "Epoch 34/50\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.9507\n",
      "Reached 95% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1334 - accuracy: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x299a9603130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "data = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
    "\n",
    "training_images = training_images/255.0 # values of training_images = 0 to 255 ----> 0 to 1\n",
    "test_images = test_images/255.0  #similaryly values of test_images changed to 0 to 1. this process is called normalizing the image.\n",
    "#normalization improves the performance\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)), # not a layer of neurons. input layer specefication, we fill flat our 2d array[28x28] to 1d array\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),# middle layer. 128 neurons, relu = rectified linear unit. it returns a value if > 0. we dont want negative values in summation\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax) # output layer. 10 neurons because 10 classes . softmax loop through all neurons and find the bigger one (each neurons will end up with a probability that the input pixel matchs the class.\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=50,\n",
    "         callbacks=[callbacks])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c238e64-3ffb-429c-be85-7a3c48637900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.4168 - accuracy: 0.8865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4168231785297394, 0.8865000009536743]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc699d8-8d5c-4f26-ac30-c34e5834803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "[4.0495835e-18 7.7424836e-20 6.9312317e-23 7.2313166e-26 4.0121317e-23\n",
      " 3.0993245e-08 5.6944390e-21 2.7879825e-05 4.6070908e-18 9.9997211e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec39e1-b6a5-4ec8-a7b2-0f1e0b07600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifications[88])\n",
    "print(test_labels[88])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16162240-c0ac-4ad9-ba95-1f234b13cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each 788 pixel is considered an array\n",
    "# 128 = middle/hidden neurons\n",
    "# 10 =output neurons\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
